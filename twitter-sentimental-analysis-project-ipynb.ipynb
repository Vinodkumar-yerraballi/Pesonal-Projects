{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/vinod123kumar/twitter-sentimental-analysis-project-ipynb?scriptVersionId=142770267\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#Import the Standard libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom wordcloud import WordCloud\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:49.327056Z","iopub.execute_input":"2023-04-26T09:33:49.327492Z","iopub.status.idle":"2023-04-26T09:33:49.334567Z","shell.execute_reply.started":"2023-04-26T09:33:49.327455Z","shell.execute_reply":"2023-04-26T09:33:49.333101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing Stage","metadata":{}},{"cell_type":"code","source":"#Load the dataset\ndata=pd.read_csv('/kaggle/input/hatred-on-twitter-during-metoo-movement/MeTooHate.csv')\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:49.339516Z","iopub.execute_input":"2023-04-26T09:33:49.339933Z","iopub.status.idle":"2023-04-26T09:33:52.680253Z","shell.execute_reply.started":"2023-04-26T09:33:49.339897Z","shell.execute_reply":"2023-04-26T09:33:52.678984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:52.682281Z","iopub.execute_input":"2023-04-26T09:33:52.682654Z","iopub.status.idle":"2023-04-26T09:33:52.864168Z","shell.execute_reply.started":"2023-04-26T09:33:52.682605Z","shell.execute_reply":"2023-04-26T09:33:52.862875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.shape","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:52.868241Z","iopub.execute_input":"2023-04-26T09:33:52.868637Z","iopub.status.idle":"2023-04-26T09:33:52.876178Z","shell.execute_reply.started":"2023-04-26T09:33:52.868589Z","shell.execute_reply":"2023-04-26T09:33:52.874891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking the null values in the data\ndata.isna().sum()/len(data)*100","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:52.879224Z","iopub.execute_input":"2023-04-26T09:33:52.879568Z","iopub.status.idle":"2023-04-26T09:33:53.056071Z","shell.execute_reply.started":"2023-04-26T09:33:52.879537Z","shell.execute_reply":"2023-04-26T09:33:53.05465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Explpore Data Analysis with data","metadata":{}},{"cell_type":"code","source":"'''\nCreate a function to checking the null values in the data with percentage\nin order wise.\n'''\ndef checking_null_values(df):\n    #we creat a for loop that will return which columns have null columns\n    na_columns=[col for col in df.columns if df[col].isna().sum()>0]\n    # We find the null values in the null columns this values or arranged in ascending format\n    na_miss=df[na_columns].isna().sum().sort_values(ascending=False)\n    #and this code will be multiplication with 100 covert in to percentage\n    ratio=(df[na_columns].isna().sum()/df.shape[0]*100).sort_values(ascending=False)\n    # then we finally concat the miss_values and percentge with np.round 2 values and finally we create a data frame\n    missing_df=pd.concat([na_miss,np.round(ratio,2)],axis=1,keys=['Null values','Percentage'])\n    missing_df=pd.DataFrame(missing_df)\n    return missing_df.style.background_gradient(cmap='winter_r')\nchecking_null_values(data)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:53.057456Z","iopub.execute_input":"2023-04-26T09:33:53.057851Z","iopub.status.idle":"2023-04-26T09:33:53.562499Z","shell.execute_reply.started":"2023-04-26T09:33:53.057811Z","shell.execute_reply":"2023-04-26T09:33:53.561286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.columns","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:53.563922Z","iopub.execute_input":"2023-04-26T09:33:53.564261Z","iopub.status.idle":"2023-04-26T09:33:53.571931Z","shell.execute_reply.started":"2023-04-26T09:33:53.56423Z","shell.execute_reply":"2023-04-26T09:33:53.570554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#See the numerical columns in the data\nnumerical=[col for col in data.columns if data[col].dtype!='object']\nnumerical","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:53.573464Z","iopub.execute_input":"2023-04-26T09:33:53.573999Z","iopub.status.idle":"2023-04-26T09:33:53.583984Z","shell.execute_reply.started":"2023-04-26T09:33:53.57395Z","shell.execute_reply":"2023-04-26T09:33:53.582293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nTwo find the Percentage of the label data and visulize with pie chart.\nin the pie chart 88% of the data is not horm and and reaming 11% is harmfull tweets.\n'''\ndata['category'].value_counts()\\\n.sort_values(ascending=False)\\\n.plot(kind='pie',explode=[0.2,0.05],\n    labels=['not-harm','harm'],\n    colors=['yellow','gray'],\n    autopct='%1.2f%%',\n    shadow=True,title=\"Percentage of the harm and not-harm twittes\",figsize=(16,5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:53.585739Z","iopub.execute_input":"2023-04-26T09:33:53.586276Z","iopub.status.idle":"2023-04-26T09:33:53.75526Z","shell.execute_reply.started":"2023-04-26T09:33:53.586225Z","shell.execute_reply":"2023-04-26T09:33:53.753812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations:\n###### 1) From the above chart we visualize the label data\n###### 2)We abserve 88% data is not harmful and remaing 12% is harmfull data","metadata":{}},{"cell_type":"code","source":"'''To visualize the top 50 countrys most twitted\n'''\ndata['location'].value_counts()[:50]\\\n.sort_values(ascending=False)\\\n.plot(kind='bar',title=\"Which location most twitted\",figsize=(17,6),color=['red','green','blue','pink','orange'])\nplt.xlabel(\"Location\")\nplt.ylabel(\"Count of location\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:53.756813Z","iopub.execute_input":"2023-04-26T09:33:53.758531Z","iopub.status.idle":"2023-04-26T09:33:54.808124Z","shell.execute_reply.started":"2023-04-26T09:33:53.758473Z","shell.execute_reply":"2023-04-26T09:33:54.806893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.groupby(['status_id'])['followers_count'].sum()[:50]\\\n.sort_values(ascending=False)\\\n.plot(kind='bar',figsize=(17,5),title=\"To visualize the follwer of the each member\",color='r')\nplt.xlabel(\"status_id\")\nplt.ylabel(\"Count of values\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:54.814306Z","iopub.execute_input":"2023-04-26T09:33:54.814699Z","iopub.status.idle":"2023-04-26T09:33:55.986933Z","shell.execute_reply.started":"2023-04-26T09:33:54.814662Z","shell.execute_reply":"2023-04-26T09:33:55.985633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To visualize the followers_count in the data\ndata['followers_count'].value_counts().sort_values(ascending=False)[:50].plot(kind='bar',figsize=(18,6),title='To visualize followers_count',color=['red','green'])\nplt.xlabel('followers_count')\nplt.ylabel('Count of followers')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:55.988762Z","iopub.execute_input":"2023-04-26T09:33:55.989164Z","iopub.status.idle":"2023-04-26T09:33:56.68367Z","shell.execute_reply.started":"2023-04-26T09:33:55.989129Z","shell.execute_reply":"2023-04-26T09:33:56.68227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:56.685297Z","iopub.execute_input":"2023-04-26T09:33:56.685692Z","iopub.status.idle":"2023-04-26T09:33:56.700763Z","shell.execute_reply.started":"2023-04-26T09:33:56.685617Z","shell.execute_reply":"2023-04-26T09:33:56.699486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['created_at']=pd.to_datetime(data['created_at'])\ndata['year']=data['created_at'].dt.year\ndata['month']=data['created_at'].dt.month\ndata['year'].value_counts().plot(kind='pie',explode=[0.2,0.05],\n    labels=['2018','2019'],\n    colors=['red','gray'],\n    autopct='%1.2f%%',\n    shadow=True,title=\"Percentage of the twitter in the year wise\",figsize=(16,5))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:56.7026Z","iopub.execute_input":"2023-04-26T09:33:56.703019Z","iopub.status.idle":"2023-04-26T09:33:57.427532Z","shell.execute_reply.started":"2023-04-26T09:33:56.702982Z","shell.execute_reply":"2023-04-26T09:33:57.425973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Observations:\n###### 1)From the above chart 83% of the tweets tweeted in the year 2018 and 16 % twittes twitted in 2019","metadata":{}},{"cell_type":"code","source":"follwer_max=data['followers_count'].max()\nfollwer_min=data['followers_count'].min()\nfriend_max=data['friends_count'].max()\nfriend_min=data['friends_count'].min()\nprint(f'the highest followers in the data is {follwer_max} ')\nprint(f'the highest followers in the data is {follwer_min}')\nprint(f'the highest friends in the data is {friend_max}')\nprint(f'the highest friends in the data is {friend_min}')","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:57.42989Z","iopub.execute_input":"2023-04-26T09:33:57.430481Z","iopub.status.idle":"2023-04-26T09:33:57.447889Z","shell.execute_reply.started":"2023-04-26T09:33:57.430431Z","shell.execute_reply":"2023-04-26T09:33:57.44588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Natural Language Process Techinques","metadata":{}},{"cell_type":"code","source":"import string\nstring.punctuation","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:57.450133Z","iopub.execute_input":"2023-04-26T09:33:57.45102Z","iopub.status.idle":"2023-04-26T09:33:57.460667Z","shell.execute_reply.started":"2023-04-26T09:33:57.450944Z","shell.execute_reply":"2023-04-26T09:33:57.459365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove the Punctuations from the data with sample question\nharm=data[data['category']==1]\nq1=harm['text'].values[0]\nq1","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:57.462559Z","iopub.execute_input":"2023-04-26T09:33:57.464591Z","iopub.status.idle":"2023-04-26T09:33:57.551525Z","shell.execute_reply.started":"2023-04-26T09:33:57.464535Z","shell.execute_reply":"2023-04-26T09:33:57.550108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We remove extra keywords in the data with sample question\ntest_punc_remove=[char for char in q1 if char not in string.punctuation]\ntest_punc_removed=''.join(test_punc_remove)\ntest_punc_removed","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:57.553302Z","iopub.execute_input":"2023-04-26T09:33:57.554458Z","iopub.status.idle":"2023-04-26T09:33:57.56377Z","shell.execute_reply.started":"2023-04-26T09:33:57.554403Z","shell.execute_reply":"2023-04-26T09:33:57.562399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_punc_removes=[]\nfor char in q1:\n    if char not in string.punctuation:\n        test_punc_removes.append(char)\npunc_remove=''.join(test_punc_removes)\npunc_remove","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:57.565168Z","iopub.execute_input":"2023-04-26T09:33:57.565548Z","iopub.status.idle":"2023-04-26T09:33:57.577141Z","shell.execute_reply.started":"2023-04-26T09:33:57.565512Z","shell.execute_reply":"2023-04-26T09:33:57.575841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def punction_remove(text):\n    if isinstance(text, float):\n        return text\n    else:\n        test_punc_remove=[char for char in text if char not in string.punctuation]\n        test_punc_removed=''.join(test_punc_remove)\n        return test_punc_removed\ndata['text']=data['text'].apply(punction_remove)","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:33:57.578694Z","iopub.execute_input":"2023-04-26T09:33:57.579092Z","iopub.status.idle":"2023-04-26T09:34:11.793274Z","shell.execute_reply.started":"2023-04-26T09:33:57.579056Z","shell.execute_reply":"2023-04-26T09:34:11.792246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['text']","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:34:11.794542Z","iopub.execute_input":"2023-04-26T09:34:11.795817Z","iopub.status.idle":"2023-04-26T09:34:11.804479Z","shell.execute_reply.started":"2023-04-26T09:34:11.795761Z","shell.execute_reply":"2023-04-26T09:34:11.803242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove the stopwords from the data\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nstopwords=','.join(stopwords.words('english'))\nstopwords","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:34:11.806035Z","iopub.execute_input":"2023-04-26T09:34:11.806382Z","iopub.status.idle":"2023-04-26T09:34:11.8182Z","shell.execute_reply.started":"2023-04-26T09:34:11.806349Z","shell.execute_reply":"2023-04-26T09:34:11.816778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization with nltk libaries","metadata":{}},{"cell_type":"code","source":"tokenize=word_tokenize(punc_remove)\ntokenize","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:34:11.81989Z","iopub.execute_input":"2023-04-26T09:34:11.820702Z","iopub.status.idle":"2023-04-26T09:34:11.829404Z","shell.execute_reply.started":"2023-04-26T09:34:11.820553Z","shell.execute_reply":"2023-04-26T09:34:11.828041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Stopwords Removel Process","metadata":{}},{"cell_type":"code","source":"def stopwords_english(text):\n    return [word for word in text if word.lower() not in stopwords]\nstopwords_remove=stopwords_english(tokenize)\nstopwords_remove","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:34:11.831135Z","iopub.execute_input":"2023-04-26T09:34:11.831597Z","iopub.status.idle":"2023-04-26T09:34:11.842249Z","shell.execute_reply.started":"2023-04-26T09:34:11.831548Z","shell.execute_reply":"2023-04-26T09:34:11.840951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stemmer=SnowballStemmer(language='english')\nstemming_process=[stemmer.stem(word) for word in stopwords_remove]\nstemming_process","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:34:11.843793Z","iopub.execute_input":"2023-04-26T09:34:11.844172Z","iopub.status.idle":"2023-04-26T09:34:11.854485Z","shell.execute_reply.started":"2023-04-26T09:34:11.844138Z","shell.execute_reply":"2023-04-26T09:34:11.853111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def stemming(text):\n    stemming=[stemmer.stem(word) for word in stopwords_remove]\n    stemming=''.join(stemming)\n    return stemming\n# lemmatizer = WordNetLemmatizer()\n# q1_lem=lemmatizer.lemmatize(stemming_process)\n# q1_lem","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:34:11.856158Z","iopub.execute_input":"2023-04-26T09:34:11.856979Z","iopub.status.idle":"2023-04-26T09:34:11.866089Z","shell.execute_reply.started":"2023-04-26T09:34:11.85693Z","shell.execute_reply":"2023-04-26T09:34:11.864653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:35:33.554501Z","iopub.execute_input":"2023-04-26T09:35:33.554984Z","iopub.status.idle":"2023-04-26T09:35:33.572184Z","shell.execute_reply.started":"2023-04-26T09:35:33.554942Z","shell.execute_reply":"2023-04-26T09:35:33.57095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_preprocessing(text):\n    #Word_tokenize\n    words=word_tokenize(text)\n    #Stop words removal\n    words=[word for word in words if word not in stopwords]\n    #Stemming process\n    words=[stemmer.stem(word) for word in words]\n    #Lemmatization\n#     words=[lemmatizer.lemmatize(word) for word in words]\n    # Convert all words to lowercase\n    words = [word.lower() for word in words]\n    words=' '.join(words)\n    return words\n\ndata['text'] = data['text'].apply(text_preprocessing)\n","metadata":{"execution":{"iopub.status.busy":"2023-04-26T09:39:45.610749Z","iopub.execute_input":"2023-04-26T09:39:45.611416Z","iopub.status.idle":"2023-04-26T09:39:45.901247Z","shell.execute_reply.started":"2023-04-26T09:39:45.611362Z","shell.execute_reply":"2023-04-26T09:39:45.899031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}